"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Table of contents","",,"IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","C1","C1","Presents the table of contents for this issue of the publication.","1941-0026","","10.1109/TEVC.2019.2915711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725824","","","","","","","","","IEEE","29 May 2019","","","IEEE","IEEE Journals"
"IEEE Transactions on Evolutionary Computation publication information","",,"IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","C2","C2","Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.","1941-0026","","10.1109/TEVC.2019.2916272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725818","","","","","","","","","IEEE","29 May 2019","","","IEEE","IEEE Journals"
"Evolutionary Many-Objective Optimization Based on Dynamical Decomposition","X. He; Y. Zhou; Z. Chen; Q. Zhang","School of Data and Computer Science and Collaborative Innovation Center of High Performance Computing, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science and Collaborative Innovation Center of High Performance Computing, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science and Collaborative Innovation Center of High Performance Computing, Sun Yat-sen University, Guangzhou, China; Department of Computer Science, City University of Hong Kong, Hong Kong","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","361","375","Decomposition-based many-objective evolutionary algorithms generally decompose the objective space into multiple subregions with the help of a set of reference vectors. The resulting subregions are fixed since the reference vectors are usually predefined. When the optimization problem has a complicated Pareto front (PF), this decomposition may decrease the algorithm performance. To deal with this problem, this paper proposes a dynamical decomposition strategy. Instead of using predefined reference vectors, solution themselves are used as reference vectors. Thus, they are adapted to the shape of PF automatically. Besides, the subregions are produced one by one through successively bipartitioning the objective space. The resulting subregions are not fixed but dynamically determined by the population solutions as well as the subregions produced previously. Based on this strategy, a solution ranking method, named dynamical-decomposition-based ranking method (DDR), is proposed which can be employed in the mating selection and environmental selection in commonly used algorithm frameworks. Compared with those in the other decomposition-based algorithms, DDR has the following properties: 1) no predefined reference vectors are required; 2) less parameters are involved; and 3) the ranking results can not only be utilized directly to select solutions but also serve as a secondary criterion in traditional Pareto-based algorithms. In this paper, DDR is equipped in two algorithm frameworks for handling many-objective optimization problems. Comparisons with five state-of-the-art algorithms on 31 widely used test problems are carried out to test the performance of the proposed approach. The experimental results have shown the effectiveness of the proposed approach in keeping a good tradeoff between convergence and diversity.","1941-0026","","10.1109/TEVC.2018.2865590","National Natural Science Foundation of China(grant numbers:61472143,61773410,61673403); Joint Research Scheme sponsored by the Research Grants Council of the Hong Kong Special Administrative Region and France National Research Agency(grant numbers:A-CityU101/16); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8437178","Dynamical decomposition;evolutionary algorithm;many-objective optimization","Optimization;Convergence;Sociology;Statistics;Heuristic algorithms;Evolutionary computation;Shape","evolutionary computation;Pareto optimisation","decomposition-based many-objective evolutionary algorithms;objective space;multiple subregions;resulting subregions;optimization problem;algorithm performance;dynamical decomposition strategy;predefined reference vectors;population solutions;solution ranking method;DDR;algorithm frameworks;decomposition-based algorithms;ranking results;traditional Pareto-based algorithms;many-objective optimization problems;state-of-the-art algorithms;dynamical-decomposition-based ranking method","","73","","64","IEEE","15 Aug 2018","","","IEEE","IEEE Journals"
"Learning to Decompose: A Paradigm for Decomposition-Based Multiobjective Optimization","M. Wu; K. Li; S. Kwong; Q. Zhang; J. Zhang","Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Computer Science, University of Exeter, Exeter, U.K.; City University of Hong Kong Shenzhen Research Institute, Shenzhen, China; City University of Hong Kong Shenzhen Research Institute, Shenzhen, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","376","390","The decomposition-based evolutionary multiobjective optimization (EMO) algorithm has become an increasingly popular choice for a posteriori multiobjective optimization. However, recent studies have shown that their performance strongly depends on the Pareto front (PF) shapes. This can be attributed to the decomposition method, of which the reference points and subproblem formulation settings are not well adaptable to various problem characteristics. In this paper, we develop a learning-to-decompose (LTD) paradigm that adaptively sets the decomposition method by learning the characteristics of the estimated PF. Specifically, it consists of two interdependent parts, i.e., a learning module and an optimization module. Given the current nondominated solutions from the optimization module, the learning module periodically learns an analytical model of the estimated PF. Thereafter, useful information is extracted from the learned model to set the decomposition method for the optimization module: 1) reference points compliant with the PF shape and 2) subproblem formulations whose contours and search directions are appropriate for the current status. Accordingly, the optimization module, which can be any decomposition-based EMO algorithm in principle, decomposes the multiobjective optimization problem into a number of subproblems and optimizes them simultaneously. To validate our proposed LTD paradigm, we integrate it with two decomposition-based EMO algorithms, and compare them with four state-of-the-art algorithms on a series of benchmark problems with various PF shapes.","1941-0026","","10.1109/TEVC.2018.2865931","Hong Kong Research Grants Council (RGC) General Research Fund(grant numbers:9042038 (CityU 11205314)); ANR/RCC Joint Research Scheme through the Hong Kong RGC and the France National Research Agency(grant numbers:A-CityU101/16); Royal Society(grant numbers:IEC/NSFC/170243); National Natural Science Foundation of China(grant numbers:61672443,61473241); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8439014","Decomposition;evolutionary computation;Gaussian process (GP) regression;multiobjective optimization;reference points generation","Optimization;Shape;Sociology;Statistics;Computer science;Self-organizing feature maps;Analytical models","evolutionary computation;Pareto optimisation","learning-to-decompose paradigm;LTD paradigm;optimization module;learning module;estimated PF;subproblem formulation settings;Pareto front shapes;posteriori multiobjective optimization;decomposition-based evolutionary multiobjective optimization algorithm;PF shape;decomposition-based EMO algorithm","","67","","55","IEEE","17 Aug 2018","","","IEEE","IEEE Journals"
"A Clustering-Based Evolutionary Algorithm for Many-Objective Optimization Problems","Q. Lin; S. Liu; K. -C. Wong; M. Gong; C. A. Coello Coello; J. Chen; J. Zhang","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Xidian University, Xi’an, China; Department of Computer Science, CINVESTAV-IPN (Evolutionary Computation Group), Mexico City, Mexico; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","391","405","This paper suggests a novel clustering-based evolutionary algorithm for many-objective optimization problems. Its main idea is to classify the population into a number of clusters, which is expected to solve the difficulty of balancing convergence and diversity in high-dimensional objective space. The individuals showing high similarities on the vector angles are gathered into the same cluster, such that the population’s distribution can be well portrayed by the clusters. To efficiently find these clusters, partitional clustering is first used to classify the union population into  ${m}$  main clusters based on the  ${m}$  axis vectors ( ${m}$  is the number of objectives), and then hierarchical clustering is further run on these  ${m}$  main clusters to get  ${N}$  final clusters ( ${N}$  is the population size and  ${N>m}$ ). At last, in environmental selection, one individual from each of  ${N}$  clusters closest to the axis vectors is selected to maintain diversity, while one individual from each of the other clusters is preferred by a simple convergence indicator to ensure convergence. When tackling some well-known test problems with 5–15 objectives, extensive experiments validate the superiority of our algorithm over six competitive many-objective EAs, especially on problems with incomplete and irregular Pareto-optimal fronts.","1941-0026","","10.1109/TEVC.2018.2866927","National Natural Science Foundation of China(grant numbers:61876110,61772393,61402291); Research Grants Council of the Hong Kong Special Administrative Region(grant numbers:CityU 21200816,CityU 11203217,CityU 11200218); Consejo Nacional de Ciencia y Tecnología(grant numbers:221551); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444681","Evolutionary algorithm (EA);hierarchical clustering;many-objective optimization;partitional clustering","Sociology;Statistics;Convergence;Phase change materials;Clustering methods;Evolutionary computation;Clustering algorithms","evolutionary computation;Pareto optimisation;pattern classification;pattern clustering;vectors","many-objective EAs;incomplete Pareto-optimal fronts;irregular Pareto-optimal fronts;many-objective optimization problems;high-dimensional objective space;vector angles;partitional clustering;union population;hierarchical clustering;population size;clustering-based evolutionary algorithm;axis vectors","","80","","69","IEEE","23 Aug 2018","","","IEEE","IEEE Journals"
"Memetic Evolution for Generic Full-Body Inverse Kinematics in Robotics and Animation","S. Starke; N. Hendrich; J. Zhang","School of Informatics, University of Edinburgh, Edinburgh, U.K.; Faculty of Mathematics Computer Science and Natural Sciences, TAMS Group, University of Hamburg, Hamburg, Germany; Faculty of Mathematics Computer Science and Natural Sciences, TAMS Group, University of Hamburg, Hamburg, Germany","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","406","420","In this paper, a novel and fast memetic evolutionary algorithm is presented which can solve fully constrained generic inverse kinematics with multiple end effectors and goal objectives, leaving high flexibility for the design of custom cost functions. The algorithm utilizes a hybridization of evolutionary and swarm optimization, combined with the limited-memory-Broyden-Fletcher-Goldfarb-Shanno with bound constraints algorithm for gradient-based optimization. Accurate solutions can be found in real-time and suboptimal extrema are robustly avoided, scaling well even for greatly higher degree of freedom. The algorithm provides a general framework for bounded continuous optimization which only requires two parameters for the number of individuals and elites to be set, and supports adding additional goals and constraints for inverse kinematics, such as minimal displacement between solutions, collision avoidance, or functional joint relations. Experimental results on several industrial and anthropomorphic robots as well as on virtual characters demonstrate the algorithm to be applicable for solving complex kinematic postures for different challenging tasks in robotics, human-robot interaction and character animation, including dexterous object manipulation, collision-free full-body motion, as well as animation post-processing for video games and films. Implementations are made available for Unity3D and robot operating system.","1941-0026","","10.1109/TEVC.2018.2867601","German Research Foundation (DFG); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449979","Artificial intelligence;character animation;collision avoidance;evolutionary computation;full-body motion;inverse kinematics;optimization;robotics","Kinematics;Geometry;End effectors;Optimization;Animation;Collision avoidance","collision avoidance;computer animation;dexterous manipulators;end effectors;evolutionary computation;gradient methods;human-robot interaction;manipulator kinematics;mobile robots;particle swarm optimisation;path planning;search problems;virtual reality","robotics;human-robot interaction;character animation;dexterous object manipulation;collision-free full-body motion;robot operating system;generic full-body inverse kinematics;multiple end effectors;high flexibility;custom cost functions;evolutionary optimization;swarm optimization;gradient-based optimization;suboptimal extrema;bounded continuous optimization;collision avoidance;functional joint relations;industrial robots;anthropomorphic robots;complex kinematic postures;memetic evolutionary algorithm;limited-memory-Broyden-Fletcher-Goldfarb-Shanno bound constraints algorithm;virtual characters;animation post-processing video games","","43","","46","OAPA","29 Aug 2018","","","IEEE","IEEE Journals"
"A Survey on Cooperative Co-Evolutionary Algorithms","X. Ma; X. Li; Q. Zhang; K. Tang; Z. Liang; W. Xie; Z. Zhu","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; School of Science (Computer Science and Software Engineering), RMIT University, Melbourne, VIC, Australia; Shenzhen Research Institute, City University of Hong Kong, Hong Kong; Shenzhen Key Laboratory of Computational Intelligence, Southern University of Science and Technology, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; ATR National Key Laboratory of Defense Technology, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","421","441","The first cooperative co-evolutionary algorithm (CCEA) was proposed by Potter and De Jong in 1994 and since then many CCEAs have been proposed and successfully applied to solving various complex optimization problems. In applying CCEAs, the complex optimization problem is decomposed into multiple subproblems, and each subproblem is solved with a separate subpopulation, evolved by an individual evolutionary algorithm (EA). Through cooperative co-evolution of multiple EA subpopulations, a complete problem solution is acquired by assembling the representative members from each subpopulation. The underlying divide-and-conquer and collaboration mechanisms enable CCEAs to tackle complex optimization problems efficiently, and hence CCEAs have been attracting wide attention in the EA community. This paper presents a comprehensive survey of these CCEAs, covering problem decomposition, collaborator selection, individual fitness evaluation, subproblem resource allocation, implementations, benchmark test problems, control parameters, theoretical analyses, and applications. The unsolved challenges and potential directions for their solutions are discussed.","1941-0026","","10.1109/TEVC.2018.2868770","National Natural Science Foundation of China(grant numbers:61471246,61603259,61871272,51405075,61672478,61473241); ANR/RCC Joint Research Scheme sponsored by the Research Grants Council of the Hong Kong Special Administrative Region, China, and France National Research Agency(grant numbers:A-CityU101/16); Guangdong Special Support Program of Top-Notch Young Professionals(grant numbers:2014TQ01X273); Fundamental Research Funds for the Central Universities(grant numbers:GK201603014,GK201603082); Department of Education of Guangdong Province(grant numbers:2016KTSCX121); Shenzhen Fundamental Research Program(grant numbers:JCYJ20150324141711587,JCYJ20170302154328155,JCYJ20170302154227954,JCGG20170414111229388); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454482","Cooperative co-evolutionary algorithm (CCEA);evolutionary algorithm (EA);genetic algorithm (GA)","Optimization;Genetic algorithms;Resource management;Benchmark testing;Computer science;Google;Perturbation methods","evolutionary computation;optimisation;resource allocation","co-evolutionary algorithm;CCEA;complex optimization problem;multiple subproblems;separate subpopulation;individual evolutionary algorithm;multiple EA subpopulations;problem decomposition;benchmark test problems;divide-and-conquer mechanism;collaboration mechanism;EA community;covering problem decomposition;collaborator selection;individual fitness evaluation;subproblem resource allocation;control parameters","","142","","242","IEEE","4 Sep 2018","","","IEEE","IEEE Journals"
"Data-Driven Evolutionary Optimization: An Overview and Case Studies","Y. Jin; H. Wang; T. Chugh; D. Guo; K. Miettinen","Department of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China; School of Artificial Intelligence, Xidian University, Xi’an, China; Department of Computer Science, University of Exeter, Exeter, U.K.; State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China; Faculty of Information Technology, University of Jyvaskyla, Finland","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","442","458","Most evolutionary optimization algorithms assume that the evaluation of the objective and constraint functions is straightforward. In solving many real-world optimization problems, however, such objective functions may not exist. Instead, computationally expensive numerical simulations or costly physical experiments must be performed for fitness evaluations. In more extreme cases, only historical data are available for performing optimization and no new data can be generated during optimization. Solving evolutionary optimization problems driven by data collected in simulations, physical experiments, production processes, or daily life are termed data-driven evolutionary optimization. In this paper, we provide a taxonomy of different data driven evolutionary optimization problems, discuss main challenges in data-driven evolutionary optimization with respect to the nature and amount of data, and the availability of new data during optimization. Real-world application examples are given to illustrate different model management strategies for different categories of data-driven optimization problems.","1941-0026","","10.1109/TEVC.2018.2869001","Engineering and Physical Sciences Research Council(grant numbers:EP/M017869/1); National Natural Science Foundation of China(grant numbers:61590922,61876123); Finland Distinguished Professor Project DeCoMo at the University of Jyvaskyla; Finnish Funding Agency for Innovation (Tekes); Natural Environment Research Council(grant numbers:NE/P017436/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456559","Data science;data-driven optimization;evolutionary algorithms (EAs);machine learning;model management;surrogate","Optimization;Data models;Computational modeling;Data mining;Sociology;Statistics;Machine learning","evolutionary computation;optimisation","data-driven evolutionary optimization;evolutionary optimization algorithms;real-world optimization problems;physical experiments;production processes;objective functions;constraint functions","","289","","120","IEEE","6 Sep 2018","","","IEEE","IEEE Journals"
"Multiobjective Infill Criterion Driven Gaussian Process-Assisted Particle Swarm Optimization of High-Dimensional Expensive Problems","J. Tian; Y. Tan; J. Zeng; C. Sun; Y. Jin","School of Data and Computer Science, Shandong Women’s University, Jinan, China; Department of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China; School of Computer Science and Control Engineering, North University of China, Taiyuan, China; Department of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China; Department of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, China","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","459","472","Model management plays an essential role in surrogate-assisted evolutionary optimization of expensive problems, since the strategy for selecting individuals for fitness evaluation using the real objective function has substantial influences on the final performance. Among many others, infill criterion driven Gaussian process (GP)-assisted evolutionary algorithms have been demonstrated competitive for optimization of problems with up to 50 decision variables. In this paper, a multiobjective infill criterion (MIC) that considers the approximated fitness and the approximation uncertainty as two objectives is proposed for a GP-assisted social learning particle swarm optimization algorithm. The MIC uses nondominated sorting for model management, thereby avoiding combining the approximated fitness and the approximation uncertainty into a scalar function, which is shown to be particularly important for high-dimensional problems, where the estimated uncertainty becomes less reliable. Empirical studies on 50-D and 100-D benchmark problems and a synthetic problem constructed from four real-world optimization problems demonstrate that the proposed MIC is more effective than existing scalar infill criteria for GP-assisted optimization given a limited computational budget.","1941-0026","","10.1109/TEVC.2018.2869247","National Natural Science Foundation of China(grant numbers:61876123,61472269,61403271,61403272); Fund Program for the Scientific Activities of Selected Returned Overseas Professionals in Shanxi Province; Northeastern University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457296","Expensive optimization;Gaussian process (GP);multiobjective infill criterion (MIC);social learning particle swarm optimization (SL-PSO)","Optimization;Uncertainty;Gaussian processes;Linear programming;Computational modeling;Particle swarm optimization","approximation theory;evolutionary computation;Gaussian processes;particle swarm optimisation","high-dimensional expensive problem;GP-assisted social learning particle swarm optimization algorithm;approximation uncertainty;approximated fitness;Gaussian process-assisted evolutionary algorithms;objective function;fitness evaluation;surrogate-assisted evolutionary optimization;model management;high-dimensional expensive problems;multiobjective infill criterion driven Gaussian process-assisted particle swarm optimization;GP-assisted optimization;scalar infill criteria;MIC;100-D benchmark problems","","112","","67","IEEE","11 Sep 2018","","","IEEE","IEEE Journals"
"Variable-Length Particle Swarm Optimization for Feature Selection on High-Dimensional Classification","B. Tran; B. Xue; M. Zhang","School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","473","487","With a global search mechanism, particle swarm optimization (PSO) has shown promise in feature selection (FS). However, most of the current PSO-based FS methods use a fix-length representation, which is inflexible and limits the performance of PSO for FS. When applying these methods to high-dimensional data, it not only consumes a significant amount of memory but also requires a high computational cost. Overcoming this limitation enables PSO to work on data with much higher dimensionality which has become more and more popular with the advance of data collection technologies. In this paper, we propose the first variable-length PSO representation for FS, enabling particles to have different and shorter lengths, which defines smaller search space and therefore, improves the performance of PSO. By rearranging features in a descending order of their relevance, we facilitate particles with shorter lengths to achieve better classification performance. Furthermore, using the proposed length changing mechanism, PSO can jump out of local optima, further narrow the search space and focus its search on smaller and more fruitful area. These strategies enable PSO to reach better solutions in a shorter time. Results on ten high-dimensional datasets with varying difficulties show that the proposed variable-length PSO can achieve much smaller feature subsets with significantly higher classification performance in much shorter time than the fixed-length PSO methods. The proposed method also outperformed the compared non-PSO FS methods in most cases.","1941-0026","","10.1109/TEVC.2018.2869405","Marsden Fund(grant numbers:VUW1509,VUW1615); Huawei Technologies(grant numbers:E2880/3663); Victoria University of Wellington(grant numbers:209862/3580,213150/3662); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458226","Classification;data mining;feature selection (FS);high-dimensional data;particle swarm optimization (PSO)","Feature extraction;Sociology;Statistics;Optimization;Particle swarm optimization;Topology;Memory management","feature selection;particle swarm optimisation;pattern classification;search problems;set theory","fix-length representation;data collection technologies;length changing mechanism;feature selection;high-dimensional classification;global search mechanism;feature subsets;particle swarm optimization;variable-length PSO-based FS methods;local optima","","157","","39","IEEE","11 Sep 2018","","","IEEE","IEEE Journals"
"Improving Generalization of Genetic Programming for Symbolic Regression With Angle-Driven Geometric Semantic Operators","Q. Chen; B. Xue; M. Zhang","Evolutionary Computation Research Group, School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; Evolutionary Computation Research Group, School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; Evolutionary Computation Research Group, School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","488","502","Geometric semantic genetic programming (GP) has recently attracted much attention. The key innovations are inducing a unimodal fitness landscape in the semantic space and providing a theoretical framework for designing geometric semantic operators. The geometric semantic operators aim to manipulate the semantics of programs by making a bounded semantic impact and generating child programs with similar or better behavior than their parents. These properties are shown to be highly related to a notable generalization improvement in GP. However, the potential ineffectiveness and difficulties in bounding the variations in these geometric operators still limits their positive effect on generalization. This paper attempts to further explore the geometry and search space of geometric operators to gain a greater generalization improvement in GP for symbolic regression. To this end, a new angle-driven selection operator and two new angle-driven geometric search operators are proposed. The angle-awareness brings new geometric properties to these geometric operators, which are expected to provide a greater leverage for approximating the target semantics in each operation, and more importantly, be resistant to overfitting. The experiments show that compared with two state-of-the-art geometric semantic operators, our angle-driven geometric operators not only drive the evolutionary process to fit the target semantics more efficiently but also improve the generalization performance. A further comparison between the evolved models shows that the new method generally produces simpler models with a much smaller size and is more likely to evolve toward the correct structure of the target models.","1941-0026","","10.1109/TEVC.2018.2869621","Marsden Fund(grant numbers:VUW1509,VUW1615); Huawei Industry Fund(grant numbers:E2880/3663); Victoria University of Wellington(grant numbers:209862/3580,213150/3662); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462796","Generalization;genetic programming (GP);geometric semantic operator;symbolic regression","Semantics;Genetic programming;Geometry;Measurement;Computational modeling;Backpropagation;Libraries","genetic algorithms;geometric programming;geometry;mathematical operators;regression analysis;search problems;semantic networks","symbolic regression;angle-driven geometric semantic operators;geometric semantic genetic programming;GP;semantic space;angle-driven selection operator;angle-driven geometric search operators;child programs generation;evolutionary process","","25","","35","IEEE","12 Sep 2018","","","IEEE","IEEE Journals"
"Multiphase Balance of Diversity and Convergence in Multiobjective Optimization","H. Seada; M. Abouhawwash; K. Deb","Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Department of Mathematics, Mansoura University, Mansoura, Egypt; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","503","513","In multiobjective optimization, defining a good solution is a multifactored process. Most existing evolutionary multi- or many-objective optimization (EMO) algorithms have utilized two factors: 1) domination and 2) crowding levels of each solution. Although these two coarse-grained factors are found to be adequate in many EMO algorithms, their relative importance in an algorithm has been a matter of great concern to many current studies. We argue that beside these issues, other more fine-grained factors are of importance. For example, since extreme objective-wise solutions are important in establishing a noise-free and stable normalization process, reaching extreme solutions is more crucial than finding other solutions. In this paper, we propose an integrated algorithm, B-NSGA-III, that produces much better convergence and diversity preservation. For this purpose, in addition to emphasizing extreme objective-wise solutions, B-NSGA-III tries to find solutions near intermediate undiscovered regions of the front. B-NSGA-III addresses critical algorithmic issues of convergence and diversity-preservation directly through recent progresses in literature and integrates all these critical fine-grained factors seamlessly in an alternating phases scheme. The proposed algorithm is shown to perform better than a number of commonly used existing methods.","1941-0026","","10.1109/TEVC.2018.2871362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468078","Evolutionary;Karush–Kuhn–Tucker proximity metric (KKTPM);local search (LS);multiobjective;optimization","Convergence;Optimization;Measurement;Search problems;Sociology;Statistics;Aggregates","genetic algorithms;Pareto optimisation","multifactored process;many-objective optimization algorithms;coarse-grained factors;EMO algorithms;fine-grained factors;extreme objective-wise solutions;stable normalization process;extreme solutions;integrated algorithm;B-NSGA-III;convergence;diversity preservation;critical algorithmic issues;diversity-preservation;multiobjective optimization","","36","","46","IEEE","19 Sep 2018","","","IEEE","IEEE Journals"
"A Covariance Matrix Self-Adaptation Evolution Strategy for Optimization Under Linear Constraints","P. Spettel; H. -G. Beyer; M. Hellwig","Research Center Process and Product Engineering, Vorarlberg University of Applied Sciences, Dornbirn, Austria; Research Center Process and Product Engineering, Vorarlberg University of Applied Sciences, Dornbirn, Austria; Research Center Process and Product Engineering, Vorarlberg University of Applied Sciences, Dornbirn, Austria","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","514","524","This paper addresses the development of a covariance matrix self-adaptation evolution strategy (CMSA-ES) for solving optimization problems with linear constraints. The proposed algorithm is referred to as linear constraint CMSA-ES (lcCMSA-ES). It uses a specially built mutation operator together with repair by projection to satisfy the constraints. The lcCMSA-ES evolves itself on a linear manifold defined by the constraints. The objective function is only evaluated at feasible search points (interior point method). This is a property often required in application domains, such as simulation optimization and finite element methods. The algorithm is tested on a variety of different test problems revealing considerable results.","1941-0026","","10.1109/TEVC.2018.2871944","Austrian Science Fund(grant numbers:P29651-N32); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8470948","Benchmarking;black-box optimization;constrained optimization;covariance matrix self-adaptation evolution strategy (CMSA-ES);interior point optimization method","Optimization;Covariance matrices;Maintenance engineering;Gaussian distribution;Linear programming;Evolutionary computation;Computational fluid dynamics","covariance matrices;evolutionary computation;finite element analysis;mathematical operators;optimisation","lcCMSA-ES;feasible search points;simulation optimization;covariance matrix self-adaptation evolution strategy;optimization problems;linear constraint CMSA-ES;mutation operator;finite element method;interior point method","","27","","45","IEEE","23 Sep 2018","","","IEEE","IEEE Journals"
"A Scalable Indicator-Based Evolutionary Algorithm for Large-Scale Multiobjective Optimization","W. Hong; K. Tang; A. Zhou; H. Ishibuchi; X. Yao","University Key Laboratory of Evolving Intelligent Systems of Guangdong Province, Southern University of Science and Technology, Shenzhen, China; University Key Laboratory of Evolving Intelligent Systems of Guangdong Province, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Technology, East China Normal University, Shanghai, China; University Key Laboratory of Evolving Intelligent Systems of Guangdong Province, Southern University of Science and Technology, Shenzhen, China; University Key Laboratory of Evolving Intelligent Systems of Guangdong Province, Southern University of Science and Technology, Shenzhen, China","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","525","537","The performance of traditional multiobjective evolutionary algorithms (MOEAs) often deteriorates rapidly as the number of decision variables increases. While some efforts were made to design new algorithms by adapting existing techniques to large-scale single-objective optimization to the MOEA context, the specific difficulties that may arise from large-scale multiobjective optimization have rarely been studied. In this paper, the exclusive challenges along with the increase of the number of variables of a multiobjective optimization problem (MOP) are examined empirically, and the popular benchmarks are categorized into three groups accordingly. Problems in the first category only require MOEAs to have stronger convergence, and can thus be mitigated using techniques employed in large-scale single-objective optimization. Problems that require MOEAs to have stronger diversification but ignore a correlation between position and distance functions are grouped as the second. The rest of the problems that pose a great challenge to the balance between diversification and convergence by considering a correlation between position and distance functions are grouped as the third. While existing large-scale MOEAs perform well on the problems in the first two categories, they suffer a significant loss when applied to those in the third category. To solve large-scale MOPs in this category, we have developed a novel indicator-based algorithm with an enhanced diversification mechanism. The proposed algorithm incorporates a new solution generator with an external archive, thus forcing the search toward different subregions of the Pareto front using a dual local search mechanism. The results obtained by applying the proposed algorithm to a wide variety of problems (108 instances in total) with up to 8192 variables demonstrate that it outperforms eight state-of-the-art approaches on the examined problems in the third category and show its advantage in the balance between diversification and convergence.","1941-0026","","10.1109/TEVC.2018.2881153","National Key Research and Development Program of China(grant numbers:2017YFB1003102); National Natural Science Foundation of China(grant numbers:61672478); Shenzhen Peacock Plan(grant numbers:KQTD2016112514355531); Program for University Key Laboratory of Guangdong Province(grant numbers:2017KSYS008); Royal Society(grant numbers:NA150123); IEEE Computational Intelligence Society Graduate Student Research(grant numbers:2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8533425","Scalability;multiobjective optimization;large-scale optimization;indicator-based evolutionary algorithm (EA)","Optimization;Convergence;Sociology;Statistics;Evolutionary computation;Generators;Benchmark testing","evolutionary computation;Pareto optimisation;search problems","scalable indicator-based evolutionary algorithm;large-scale multiobjective optimization;MOEA context;distance functions;large-scale MOEAs;large-scale MOPs;indicator-based algorithm;convergence;decision variables","","85","","47","IEEE","13 Nov 2018","","","IEEE","IEEE Journals"
"Introducing IEEE Collabratec","",,"IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","538","538","Advertisement, IEEE. IEEE Collabratec is a new, integrated online community where IEEE members, researchers, authors, and technology professionals with similar fields of interest can network and collaborate, as well as create and manage content. Featuring a suite of powerful online networking and collaboration tools, IEEE Collabratec allows you to connect according to geographic location, technical interests, or career pursuits. You can also create and share a professional identity that showcases key accomplishments and participate in groups focused around mutual interests, actively learning from and contributing to knowledgeable communities. All in one place! Learn about IEEE Collabratec at ieeecollabratec.org.","1941-0026","","10.1109/TEVC.2019.2916275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725809","","","","","","","","","IEEE","29 May 2019","","","IEEE","IEEE Journals"
"IEEE Open Access Publishing","",,"IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","539","539","Advertisement, IEEE.","1941-0026","","10.1109/TEVC.2019.2916276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725821","","","","","","","","","IEEE","29 May 2019","","","IEEE","IEEE Journals"
"Imagine a community hopeful for the future","",,"IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","540","540","Advertisement, IEEE.","1941-0026","","10.1109/TEVC.2019.2916277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725807","","","","","","","","","IEEE","29 May 2019","","","IEEE","IEEE Journals"
"IEEE Transactions on Evolutionary Computation Society Information","",,"IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","C3","C3","Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.","1941-0026","","10.1109/TEVC.2019.2916273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725810","","","","","","","","","IEEE","29 May 2019","","","IEEE","IEEE Journals"
"IEEE Transactions on Evolutionary Computation information for authors","",,"IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","C4","C4","These instructions give guidelines for preparing papers for this publication. Presents information for authors publishing in this journal.","1941-0026","","10.1109/TEVC.2019.2916274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725808","","","","","","","","","IEEE","29 May 2019","","","IEEE","IEEE Journals"
