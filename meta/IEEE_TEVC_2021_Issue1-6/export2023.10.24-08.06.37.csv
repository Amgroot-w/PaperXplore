"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Table of contents","",,"IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","C1","809","Presents the table of contents for this issue of the publication.","1941-0026","","10.1109/TEVC.2021.3099880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552971","","","","","","","","","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"IEEE Transactions on Evolutionary Computation Publication Information","",,"IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","C2","C2","Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.","1941-0026","","10.1109/TEVC.2021.3101531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552968","","","","","","","","","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"Guest Editorial Evolutionary Computation Meets Deep Learning","W. Ding; W. Pedrycz; G. G. Yen; B. Xue","School of Information Science and Technology, Nantong University, Nantong, China; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","810","814","Deep learning is a timely research direction in machine learning, where breakthrough progress has been made in both academe and industries, bringing promising results in speech recognition, computer vision, industrial control and automation, etc. The motivation of deep learning is primarily to establish a model to simulate the neural connection structure of the human brain. While dealing with complex tasks, deep learning adopts a number of transformation stages to deliver the in-depth description and interpretation of the data. Deep learning achieves exceptional power and flexibility by learning to represent the task through a nested hierarchy of layers, with more abstract representations formed successively in terms of less abstract ones. One of the key issues of existing deep learning approaches is that the meaningful representations can be learned only when their hyperparameter settings are properly specified beforehand, and general parameters are learned during the training process. Until now, not much research has been dedicated to automatically set the hyperparameters, and accurately find the globally optimal general parameters. However, this problem can be formulated as optimization problems, including discrete optimization, constrained optimization, large-scale global optimization, and multiobjective optimization, by engaging mechanisms of evolutionary computation.","1941-0026","","10.1109/TEVC.2021.3096336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552976","","","","","","","","0","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"Evolving Deep Convolutional Variational Autoencoders for Image Classification","X. Chen; Y. Sun; M. Zhang; D. Peng","College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu, China","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","815","829","Variational autoencoders (VAEs) have demonstrated their superiority in unsupervised learning for image processing in recent years. The performance of the VAEs highly depends on their architectures, which are often handcrafted by the human expertise in deep neural networks (DNNs). However, such expertise is not necessarily available to each of the end users interested. In this article, we propose a novel method to automatically design optimal architectures of VAEs for image classification, called evolving deep convolutional VAE (EvoVAE), based on a genetic algorithm (GA). In the proposed EvoVAE algorithm, the traditional VAEs are first generalized to a more generic and asymmetrical one with four different blocks, and then a variable-length gene encoding mechanism of the GA is presented to search for the optimal network depth. Furthermore, an effective genetic operator is designed to adapt to the proposed variable-length gene encoding strategy. To verify the performance of the proposed algorithm, nine variants of AEs and VAEs are chosen as the peer competitors to perform the comparisons on MNIST, street view house numbers, and CIFAR-10 benchmark datasets. The experiments reveal the superiority of the proposed EvoVAE algorithm, which wins 21 times out of the 24 comparisons and outperforms the best competitors by 1.39%, 14.21%, and 13.03% on the three benchmark datasets, respectively.","1941-0026","","10.1109/TEVC.2020.3047220","National Natural Science Foundation of China(grant numbers:61971296,U19A2078,61836011); Sichuan Science and Technology Planning Project(grant numbers:2020YFG0319,2020YFH0186); Fundamental Research Funds for the Central Universities(grant numbers:YJ201934); Chengdu Key Research and Development Support Plan(grant numbers:2019-YF08-00264-GX); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306892","Convolutional variational autoencoder;evolving deep learning;genetic algorithm (GA);neural architecture search (NAS)","Computer architecture;Encoding;Task analysis;Approximation algorithms;Training;Genetic algorithms;Computer science","convolutional neural nets;deep learning (artificial intelligence);genetic algorithms;image classification;unsupervised learning","GA;optimal network depth;effective genetic operator;variable-length gene encoding strategy;EvoVAE algorithm;evolving deep convolutional variational autoencoders;image classification;unsupervised learning;image processing;human expertise;deep neural networks;optimal architectures;deep convolutional VAE;genetic algorithm;traditional VAE;variable-length gene encoding mechanism","","13","","66","IEEE","24 Dec 2020","","","IEEE","IEEE Journals"
"AS-NAS: Adaptive Scalable Neural Architecture Search With Reinforced Evolutionary Algorithm for Deep Learning","T. Zhang; C. Lei; Z. Zhang; X. -B. Meng; C. L. P. Chen","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","830","841","Neural architecture search (NAS) is a challenging problem in the design of deep learning due to its nonconvexity. To address this problem, an adaptive scalable NAS method (AS-NAS) is proposed based on the reinforced I-Ching divination evolutionary algorithm (IDEA) and variable-architecture encoding strategy. First, unlike the typical reinforcement learning (RL)-based and evolutionary algorithm (EA)-based NAS methods, a simplified RL algorithm is developed and used as the reinforced operator controller to adaptively select the efficient operators of IDEA. Without the complex actor–critic parts, the reinforced IDEA based on simplified RL can enhance the search efficiency of the original EA with lower computational cost. Second, a variable-architecture encoding strategy is proposed to encode neural architecture as a fixed-length binary string. By simultaneously considering variable layers, channels, and connections between different convolution layers, the deep neural architecture can be scalable. Through the integration with the reinforced IDEA and variable-architecture encoding strategy, the design of the deep neural architecture can be adaptively scalable. Finally, the proposed AS-NAS are integrated with the  ${L}_{1/2}$  regularization to increase the sparsity of the optimized neural architecture. Experiments and comparisons demonstrate the effectiveness and superiority of the proposed method.","1941-0026","","10.1109/TEVC.2021.3061466","National Key Research and Development Program of China(grant numbers:2019YFB1703600,2019YFA0706200); National Natural Science Foundation of China(grant numbers:62076102,U1813203,U1801262,62006081); National Natural Science Foundation of Guangdong for Distinguished Young Scholar(grant numbers:2020B1515020041); Science and Technology Major Project of Guangzhou(grant numbers:202007030006); Science and Technology Program of Guangzhou(grant numbers:202002030250); Guangdong–Hong Kong–Macao Greater Bay Area Center for Brain Science and Brain-Inspired Intelligence Fund(grant numbers:2019016); China Postdoctoral Science Foundation(grant numbers:2020M672630); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9360872","Deep learning;I-Ching divination evolutionary algorithm (IDEA);neural architecture search (NAS);reinforced operator controller;variable-architecture encoding","Computer architecture;Encoding;Task analysis;Microprocessors;Aerospace electronics;Computational modeling;Search problems","convolutional neural nets;deep learning (artificial intelligence);evolutionary computation;search problems","adaptive scalable neural architecture search;reinforced evolutionary algorithm;deep learning;adaptive scalable NAS method;AS-NAS;variable-architecture encoding strategy;simplified RL algorithm;reinforced operator controller;reinforced IDEA;deep neural architecture;optimized neural architecture;reinforced I-Ching divination evolutionary algorithm;fixed-length binary string;convolution layers","","32","","56","IEEE","23 Feb 2021","","","IEEE","IEEE Journals"
"Task Allocation on Layered Multiagent Systems: When Evolutionary Many-Objective Optimization Meets Deep Q-Learning","M. Li; Z. Wang; K. Li; X. Liao; K. Hone; X. Liu","College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Department of Computer Science, Brunel University London, Uxbridge, U.K.; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Collaborative Innovation Center of High Performance Computing, National University of Defense Technology, Changsha, China; Department of Computer Science, Brunel University London, Uxbridge, U.K.; Department of Computer Science, Brunel University London, Uxbridge, U.K.","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","842","855","This article is concerned with the multitask multiagent allocation problem via many-objective optimization for multiagent systems (MASs). First, a novel layered MAS model is constructed to address the multitask multiagent allocation problem that includes both the original task simplification and the many-objective allocation. In the first layer of the model, the deep Q-learning method is introduced to simplify the prioritization of the original task set. In the second layer of the model, the modified shift-based density estimation (MSDE) method is put forward to improve the conventional strength Pareto evolutionary algorithm 2 (SPEA2) in order to achieve many-objective optimization on task assignments. Then, an MSDE-SPEA2-based method is proposed to tackle the many-objective optimization problem with objectives including task allocation, makespan, agent satisfaction, resource utilization, task completion, and task waiting time. As compared with the existing allocation methods, the developed method in this article exhibits an outstanding feature that the task assignment and the task scheduling are carried out simultaneously. Finally, extensive experiments are conducted to: 1) verify the validity of the proposed model and the effectiveness of two main algorithms and 2) illustrate the optimal solution for task allocation and efficient strategy for task scheduling under different scenarios.","1941-0026","","10.1109/TEVC.2021.3049131","National Key Research and Development Program of China(grant numbers:2020YFB2104000); National Natural Science Foundation of China(grant numbers:61625202,61751204,61860206011); European Union’s Horizon 2020 Research and Innovation Programme(grant numbers:820776 (INTEGRADDE)); Royal Society of the U.K.; Alexander von Humboldt Foundation of Germany; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9313054","Deep Q-learning (DQL);evolutionary computation;many-objective optimization;multiagent systems (MAS);task allocation","Task analysis;Resource management;Optimization;Multi-agent systems;Heuristic algorithms;Estimation;Deep learning","evolutionary computation;learning (artificial intelligence);multi-agent systems;Pareto optimisation;scheduling","task allocation;multiagent systems;multitask multiagent allocation problem;MAS model;original task simplification;deep Q-learning method;density estimation method;conventional strength Pareto evolutionary algorithm 2;MSDE-SPEA2-based method;objective optimization problem;task completion;task waiting time;task scheduling;optimal solution;evolutionary many objective optimization","","15","","64","IEEE","5 Jan 2021","","","IEEE","IEEE Journals"
"Robust Multimodal Representation Learning With Evolutionary Adversarial Attention Networks","F. Huang; A. Jolfaei; A. K. Bashir","College of Cyber Security, Jinan University, Guangzhou, China; Department of Computing, Macquarie University, Sydney, NSW, Australia; Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, U.K.","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","856","868","Multimodal representation learning is beneficial for many multimedia-oriented applications, such as social image recognition and visual question answering. The different modalities of the same instance (e.g., a social image and its corresponding description) are usually correlational and complementary. Most existing approaches for multimodal representation learning are not effective to model the deep correlation between different modalities. Moreover, it is difficult for these approaches to deal with the noise within social images. In this article, we propose a deep learning-based approach named evolutionary adversarial attention networks (EAANs), which combines the attention mechanism with adversarial networks through evolutionary training, for robust multimodal representation learning. Specifically, a two-branch visual-textual attention model is proposed to correlate visual and textual content for joint representation. Then adversarial networks are employed to impose regularization upon the representation by matching its posterior distribution to the given priors. Finally, the attention model and adversarial networks are integrated into an evolutionary training framework for robust multimodal representation learning. Extensive experiments have been conducted on four real-world datasets, including PASCAL, MIR, CLEF, and NUS-WIDE. Substantial performance improvements on the tasks of image classification and tag recommendation demonstrate the superiority of the proposed approach.","1941-0026","","10.1109/TEVC.2021.3066285","National Natural Science Foundation of China(grant numbers:61906075,62002068,61932010,61932011,61972178,61906074); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019A1515011920,2019B1515120010,2019A1515011276,2019A1515011753); Guangdong Provincial Key R&D Plan(grant numbers:2019B1515120010,202020022911500032,2019B010136003); Science and Technology Program of Guangzhou, China(grant numbers:202007040004); National Key R&D Plan2020(grant numbers:2020YFB1005600); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380546","Adversarial networks;attention model;evolutionary;multimodal;representation learning","Visualization;Correlation;Training;Data models;Task analysis;Knowledge discovery;Generative adversarial networks","deep learning (artificial intelligence);image classification;image recognition;image representation;question answering (information retrieval)","social image recognition;deep learning-based approach;evolutionary adversarial attention networks;adversarial networks;robust multimodal representation learning;two-branch visual-textual attention model;joint representation;PASCAL;MIR;CLEF;NUS-WIDE;image classification;tag recommendation","","10","","58","IEEE","17 Mar 2021","","","IEEE","IEEE Journals"
"Convolutional Neural Networks-Based Lung Nodule Classification: A Surrogate-Assisted Evolutionary Algorithm for Hyperparameter Optimization","M. Zhang; H. Li; S. Pan; J. Lyu; S. Ling; S. Su","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Information and Communication Engineering, Harbin Engineering University, Harbin, China; Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","869","882","This article investigates deep neural networks (DNNs)-based lung nodule classification with hyperparameter optimization. Hyperparameter optimization in DNNs is a computationally expensive problem, and a surrogate-assisted evolutionary algorithm has been recently introduced to automatically search for optimal hyperparameter configurations of DNNs, by applying computationally efficient surrogate models to approximate the validation error function of hyperparameter configurations. Different from existing surrogate models adopting stationary covariance functions (kernels) to measure the difference between hyperparameter points, this article proposes a nonstationary kernel that allows the surrogate model to adapt to functions whose smoothness varies with the spatial location of inputs. A multilevel convolutional neural network (ML-CNN) is built for lung nodule classification, and the hyperparameter configuration is optimized by the proposed nonstationary kernel-based Gaussian surrogate model. Our algorithm searches with a surrogate for optimal setting via a hyperparameter importance-based evolutionary strategy, and the experiments demonstrate our algorithm outperforms manual tuning and several well-established hyperparameter optimization methods, including random search, grid search, the tree-structured parzen estimator (TPE) approach, Gaussian processes (GP) with stationary kernels, and the recently proposed hyperparameter optimization via RBF and dynamic (HORD) coordinate search.","1941-0026","","10.1109/TEVC.2021.3060833","National Natural Science Foundation of China (NSFC)(grant numbers:82072007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359655","AutoML;evolutionary algorithm;hyperparameter optimization;lung nodule classification;nonstationary kernel","Optimization;Kernel;Neural networks;Lung;Feature extraction;Gaussian processes;Convolutional neural networks","cancer;convolutional neural nets;evolutionary computation;function approximation;Gaussian processes;image classification;learning (artificial intelligence);lung;medical image processing;optimisation;search problems;trees (mathematics)","convolutional neural networks-based lung nodule classification;surrogate-assisted evolutionary algorithm;deep neural networks-based lung nodule classification;DNNs;optimal hyperparameter configurations;computationally efficient surrogate models;multilevel convolutional neural network;nonstationary kernel-based Gaussian surrogate model;optimal setting;hyperparameter importance-based evolutionary strategy;hyperparameter optimization methods;RBF;dynamic coordinate search;tree-structured parzen estimator approach;random search;grid search;stationary covariance functions;validation error function approximation","","34","","61","IEEE","19 Feb 2021","","","IEEE","IEEE Journals"
"Evolutionary Deep Fusion Method and its Application in Chemical Structure Recognition","X. Liang; Q. Guo; Y. Qian; W. Ding; Q. Zhang","Institute of Big Data Science and Industry, Shanxi University, Taiyuan, China; Institute of Big Data Science and Industry, Shanxi University, Taiyuan, China; Institute of Big Data Science and Industry, Shanxi University, Taiyuan, China; School of Information Science and Technology, Nantong University, Nantong, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","883","893","Feature extraction is a critical issue in many machine learning systems. A number of basic fusion operators have been proposed and studied. This article proposes an evolutionary algorithm, called evolutionary deep fusion method, for searching an optimal combination scheme of different basic fusion operators to fuse multiview features. We apply our proposed method to chemical structure recognition. Our proposed method can directly take images as inputs, and users do not need to transform images to other formats. The experimental results demonstrate that our proposed method can achieve a better performance than those designed by human experts on this real-life problem.","1941-0026","","10.1109/TEVC.2021.3064943","National Key Research and Development Program of China(grant numbers:2018YFB1004300); National Natural Science Fund of China(grant numbers:61672332,61432011,61976129,61976120,61502289); Key Research and Development Program (International Science and Technology Cooperation Project) of Shanxi Province, China(grant numbers:201903D421003); Program for the Young San Jin Scholars of Shanxi(grant numbers:2016769); Young Scientists Fund of the National Natural Science Foundation of China(grant numbers:61802238,61906115,61603228,62006146,61906114); Shanxi Province Science Foundation for Youths(grant numbers:201901D211169,201901D211170,201901D211171); Research Project Supported by Shanxi Scholarship Council of China(grant numbers:HGKY2019001); Scientific and Technologial Innovation Programs of Higher Education Institutions in Shanxi(grant numbers:2020L0036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373673","Deep learning;evolutionary algorithms (EAs);molecular structure recognition;multiview fusion","Feature extraction;Neural networks;Chemical elements;Network architecture;Evolutionary computation;Search problems;Computational modeling","evolutionary computation;feature extraction;image fusion;image recognition;learning (artificial intelligence)","chemical structure recognition;feature extraction;machine learning systems;evolutionary algorithm;called evolutionary deep fusion method;optimal combination scheme;different basic fusion operators;multiview features","","13","","55","IEEE","9 Mar 2021","","","IEEE","IEEE Journals"
"A Survey on Evolutionary Construction of Deep Neural Networks","X. Zhou; A. K. Qin; M. Gong; K. C. Tan","Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, VIC, Australia; International Research Center for Intelligent Perception and Computation, Xidian University, Xi’an, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","894","912","Automated construction of deep neural networks (DNNs) has become a research hot spot nowadays because DNN’s performance is heavily influenced by its architecture and parameters, which are highly task-dependent, but it is notoriously difficult to find the most appropriate DNN in terms of architecture and parameters to best solve a given task. In this work, we provide an insight into the automated DNN construction process by formulating it into a multilevel multiobjective large-scale optimization problem with constraints, where the nonconvex, nondifferentiable, and black-box nature of this problem make evolutionary algorithms (EAs) to stand out as a promising solver. Then, we give a systematical review of existing evolutionary DNN construction techniques from different aspects of this optimization problem and analyze the pros and cons of using EA-based methods in each aspect. This work aims to help DNN researchers to better understand why, where, and how to utilize EAs for automated DNN construction and meanwhile, help EA researchers to better understand the task of automated DNN construction so that they may focus more on EA-favored optimization scenarios to devise more effective techniques.","1941-0026","","10.1109/TEVC.2021.3079985","National Key Research and Development Project, Ministry of Science and Technology, China(grant numbers:2018AAA0101301); National Natural Science Foundation of China(grant numbers:61876162); Research Grants Council of the Hong Kong SAR(grant numbers:PolyU11202418,PolyU11209219); Australian Research Council (ARC)(grant numbers:LP180100114,DP200102611); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430615","Automated design of DNNs;deep neural networks;evolutionary algorithms;optimization","Optimization;Computer architecture;Task analysis;Data models;Mathematical model;Computational modeling;Search problems","deep learning (artificial intelligence);evolutionary computation;genetic algorithms;neural nets","evolutionary construction;deep neural networks;automated construction;research hot spot;DNN performance;automated DNN construction process;large-scale optimization problem;nonconvex box nature;black-box nature;evolutionary algorithms;evolutionary DNN construction techniques;EA-based methods;DNN researchers;EA-favored optimization scenarios","","30","","208","CCBY","13 May 2021","","","IEEE","IEEE Journals"
"Adaptive Genetic Algorithm-Aided Neural Network With Channel State Information Tensor Decomposition for Indoor Localization","M. Zhou; Y. Long; W. Zhang; Q. Pu; Y. Wang; W. Nie; W. He","School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Software, Northwestern Polytechnical University, Xi’an, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","913","927","Channel state information (CSI) can provide phase and amplitude of multichannel subcarrier to better describe signal propagation characteristics. Therefore, CSI has become one of the most commonly used features in indoor Wi-Fi localization. In addition, compared to the CSI geometric localization method, the CSI fingerprint localization method has the advantages of easy implementation and high accuracy. However, as the scale of the fingerprint database increases, the training cost and processing complexity of CSI fingerprints will also greatly increase. Based on this, this article proposes to combine backpropagation neural network (BPNN) and adaptive genetic algorithm (AGA) with CSI tensor decomposition for indoor Wi-Fi fingerprint localization. Specifically, the tensor decomposition algorithm based on the parallel factor (PARAFAC) analysis model and the alternate least squares (ALSs) iterative algorithm are combined to reduce the interference of the environment. Then, we use the tensor wavelet decomposition algorithm for feature extraction and obtain the CSI fingerprint. Finally, in order to find the optimal weights and thresholds and then obtain the estimated location coordinates, we introduce an AGA to optimize BPNN. The experimental results show that the proposed algorithm has high localization accuracy, while improving the data processing ability and fitting the nonlinear relationship between CSI location fingerprints and location coordinates.","1941-0026","","10.1109/TEVC.2021.3085906","Science and Technology Research Program of Chongqing Municipal Education Commission(grant numbers:KJZD-K202000605,KJQN202000630); Chongqing Natural Science Foundation Project(grant numbers:cstc2020jcyj-msxmX0842,cstc2020jcyj-msxmX0865); National Natural Science Foundation of China(grant numbers:61771083,61771209); Program for Changjiang Scholars and Innovative Research Team in the University(grant numbers:IRT1299); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446615","Channel state information (CSI);fingerprint localization;genetic algorithm;neural network;tensor decomposition","Location awareness;Tensors;Noise reduction;Feature extraction;Wireless fidelity;Neural networks;Genetic algorithms","backpropagation;feature extraction;genetic algorithms;indoor communication;indoor radio;iterative methods;neural nets;tensors;wavelet transforms;wireless LAN","CSI fingerprint localization method;fingerprint database increases;training cost;backpropagation neural network;CSI tensor decomposition;indoor Wi-Fi fingerprint localization;tensor decomposition algorithm;parallel factor analysis model;tensor wavelet decomposition algorithm;high localization accuracy;CSI location fingerprints;adaptive genetic algorithm-aided neural network;channel state information tensor decomposition;indoor localization;multichannel subcarrier;signal propagation characteristics;indoor Wi-Fi localization;CSI geometric localization method","","51","","31","IEEE","3 Jun 2021","","","IEEE","IEEE Journals"
"Two-Stage Evolutionary Neural Architecture Search for Transfer Learning","Y. -W. Wen; S. -H. Peng; C. -K. Ting","Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi, Taiwan; Department of Power Mechanical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Power Mechanical Engineering, National Tsing Hua University, Hsinchu, Taiwan","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","928","940","Convolutional neural networks (CNNs) have achieved state-of-the-art performance in many image classification tasks. However, training a deep CNN requires a massive amount of training data, which can be expensive or unobtainable in practical applications, such as defect inspection and medical diagnosis. Transfer learning has been developed to address this issue by transferring knowledge learned from source domains to target domains. A common approach is fine-tuning, which adapts the parameters of a trained neural network for the new target task. Nevertheless, the network architecture remains designed for the source task rather than the target task. To optimize the network architecture in transfer learning, we propose a two-stage evolutionary neural architecture search for transfer learning (EvoNAS-TL), which searches for an efficient subnetwork of the source model for the target task. EvoNAS-TL features two search stages: 1) structure search and 2) local enhancement. The former conducts a coarse-grained global search for suitable neural architectures, while the latter acts as a fine-grained local search to refine the models obtained. In this study, neural architecture search (NAS) is formulated as a multiobjective optimization problem that concurrently minimizes the prediction error and model size. The knee-guided multiobjective evolutionary algorithm, a modern multiobjective optimization approach, is employed to solve the NAS problem. In this study, several experiments are conducted to examine the effectiveness of EvoNAS-TL. The results show that applying EvoNAS-TL on VGG-16 can reduce the model size by 52%–85% and simultaneously improve the testing accuracy by 0.7%–6.9% in transferring from ImageNet to CIFAR-10 and NEU surface detection datasets. In addition, EvoNAS-TL performs comparably to or better than state-of-the-art methods on the CIFAR-10, NEU, and Office-31 datasets.","1941-0026","","10.1109/TEVC.2021.3097937","Ministry of Science and Technology of Taiwan(grant numbers:MOST 110-2634-F-007-026,MOST 110-2221-E-007-082-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9488292","Convolutional neural network (CNN);multiobjective evolutionary algorithm;neural architecture search (NAS);transfer learning","Task analysis;Transfer learning;Computer architecture;Computational modeling;Network architecture;Optimization;Evolutionary computation","convolution;evolutionary computation;image classification;learning (artificial intelligence);neural nets;optimisation;search problems","coarse-grained global search;suitable neural architectures;fine-grained local search;knee-guided multiobjective evolutionary algorithm;modern multiobjective optimization approach;EvoNAS-TL performs;two-stage evolutionary neural architecture search;transfer learning;convolutional neural networks;image classification tasks;training data;defect inspection;medical diagnosis;source domains;trained neural network;target task;network architecture;source task;source model;EvoNAS-TL features two search stages","","9","","64","IEEE","16 Jul 2021","","","IEEE","IEEE Journals"
"A Fast Kriging-Assisted Evolutionary Algorithm Based on Incremental Learning","D. Zhan; H. Xing","School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","941","955","Kriging models, also known as Gaussian process models, are widely used in surrogate-assisted evolutionary algorithms (SAEAs). However, the cubic time complexity of the standard Kriging models limits their usage in high-dimensional optimization. To tackle this problem, we propose an incremental Kriging model for high-dimensional surrogate-assisted evolutionary computation. The main idea is to update the Kriging model incrementally based on the equations of the previously trained model instead of building the model from scratch when new samples arrive, so that the time complexity of updating the Kriging models can be reduced to quadratic. The proposed incremental learning scheme is very suitable for online SAEAs since they evaluate new samples in each one or several generations. The proposed algorithm is able to achieve competitive optimization results on the test problems compared with the standard Kriging-assisted evolutionary algorithm and is significantly faster than the standard Kriging approach. The proposed algorithm also shows competitive or better performances compared with four fast Kriging-assisted evolutionary algorithms and four state-of-the-art SAEAs. This work provides a fast way of employing Kriging models in high-dimensional surrogate-assisted evolutionary computation.","1941-0026","","10.1109/TEVC.2021.3067015","Fundamental Research Funds for the Central Universities(grant numbers:2682020CX86); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381509","Expensive optimization;high-dimensional optimization;incremental learning;Kriging models;surrogate-assisted evolutionary algorithms (SAEAs)","Computational modeling;Optimization;Training;Evolutionary computation;Data models;Mathematical model;Computational efficiency","evolutionary computation;Gaussian processes;learning (artificial intelligence);optimisation;search problems;statistical analysis","surrogate-assisted evolutionary computation;fast Kriging-assisted evolutionary algorithm;Gaussian process models;surrogate-assisted evolutionary algorithms;standard Kriging models;incremental Kriging model;trained model;incremental learning scheme;cubic time complexity","","28","","49","IEEE","18 Mar 2021","","","IEEE","IEEE Journals"
"Fast Immune System-Inspired Hypermutation Operators for Combinatorial Optimization","D. Corus; P. S. Oliveto; D. Yazdani","Computer Engineering Department, Kadir Has University, Istanbul, Turkey; Department of Computer Science, University of Sheffield, Sheffield, U.K; Department of Computer Science, Advanced Reasoning Group, Aberystwyth University, Aberystwyth, U.K","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","956","970","Various studies have shown that immune system-inspired hypermutation operators can allow artificial immune systems (AIS) to be very efficient at escaping local optima of multimodal optimization problems. However, this efficiency comes at the expense of considerably slower runtimes during the exploitation phase compared to the standard evolutionary algorithms. We propose modifications to the traditional hypermutations with mutation potential (HMP) that allow them to be efficient at exploitation, as well as maintaining their effective explorative characteristics. Rather than deterministically evaluating fitness after each bit-flip of a hypermutation, we sample the fitness function stochastically with a “parabolic” distribution. This allows the stop at the first constructive mutation (FCM) variant of HMP to reduce the linear amount of wasted function evaluations when no improvement is found to a constant. The stochastic distribution also allows the removal of the FCM mechanism altogether as originally desired in the design of the HMP operators. We rigorously prove the effectiveness of the proposed operators for all the benchmark functions, where the performance of HMP is rigorously understood in the literature. We validate the gained insights to show linear speed-ups for the identification of high-quality approximate solutions to classical NP-Hard problems from combinatorial optimization. We then show the superiority of the HMP operators to the traditional ones in an analysis of the complete standard Opt-IA AIS, where the stochastic evaluation scheme allows HMP and aging operators to work in harmony. Through a comparative performance study of other “fast mutation” operators from the literature, we conclude that a power-law distribution for the parabolic evaluation scheme is the best compromise in black-box scenarios, where little problem knowledge is available.","1941-0026","","10.1109/TEVC.2021.3068574","EPSRC(grant numbers:EP/M004252/1); 2020 University of Sheffield Postgraduate Research Student Publication Scholarship Scheme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385420","Artificial immune systems (AISs);hypermutation;runtime analysis","Standards;Runtime;Optimization;Aging;Benchmark testing;Immune system;Artificial intelligence","artificial immune systems;combinatorial mathematics;evolutionary computation;optimisation;stochastic processes","artificial immune systems;multimodal optimization problems;considerably slower runtimes;exploitation phase;standard evolutionary algorithms;traditional hypermutations;fitness function;parabolic distribution;constructive mutation variant;wasted function evaluations;stochastic distribution;HMP operators;benchmark functions;classical NP-Hard problems;combinatorial optimization;complete standard Opt-IA AIS;stochastic evaluation scheme;aging operators;fast mutation operators;parabolic evaluation scheme;fast immune system inspired hypermutation operators","","6","","48","IEEE","24 Mar 2021","","","IEEE","IEEE Journals"
"Solving Mixed Pareto-Lexicographic Multiobjective Optimization Problems: The Case of Priority Levels","L. Lai; L. Fiaschi; M. Cococcioni; K. Deb","Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","971","985","This article concerns the study of mixed Pareto-lexicographic multiobjective optimization problems where the objectives must be partitioned in multiple priority levels (PLs). A PL is a group of objectives having the same importance in terms of optimization and subsequent decision making, while between PLs a lexicographic ordering exists. A naive approach would be to define a multilevel dominance relationship and apply a standard EMO/EMaO algorithm, but the concept does not conform to a stable optimization process as the resulting dominance relationship violates the transitive property needed to achieve consistent comparisons. To overcome this, we present a novel approach that merges a custom nondominance relation with the Grossone methodology, a mathematical framework to handle infinite and infinitesimal quantities. The proposed method is implemented on a popular multiobjective optimization algorithm (NSGA-II), deriving a generalization of it called by us PL-NSGA-II. We also demonstrate the usability of our strategy by quantitatively comparing the results obtained by PL-NSGA-II against other priority and nonpriority-based approaches. Among the test cases, we include two real-world applications: one 10-objective aircraft design problem and one 3-objective crash safety vehicle design task. The obtained results show that PL-NSGA-II is more suited to solve lexicographical many-objective problems than the general purpose EMaO algorithms.","1941-0026","","10.1109/TEVC.2021.3068816","Italian Ministry of Education and Research (MIUR) in the framework of the CrossLab project (Departments of Excellence); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388902","Evolutionary computation;genetic algorithms;grossone methodology (GM);lexicographic optimization;multiobjective optimization;numerical infinitesimals","Optimization;Standards;Search problems;Automobiles;Safety;Pareto optimization;Focusing","aircraft;decision making;design engineering;genetic algorithms;impact testing;Pareto optimisation;vehicle dynamics","multiple priority levels;subsequent decision making;lexicographic ordering;naive approach;multilevel dominance relationship;stable optimization process;resulting dominance relationship;custom nondominance relation;popular multiobjective optimization algorithm;PL-NSGA-II;nonpriority-based approaches;10-objective aircraft design problem;3-objective crash safety vehicle design task;many-objective problems;general purpose EMaO algorithms;mixed Pareto-lexicographic multiobjective optimization problems;Grossone methodology;infinitesimal quantities","","5","","38","IEEE","29 Mar 2021","","","IEEE","IEEE Journals"
"CDE-GAN: Cooperative Dual Evolution-Based Generative Adversarial Network","S. Chen; W. Wang; B. Xia; X. You; Q. Peng; Z. Cao; W. Ding","School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; STEM, University of South Australia, Adelaide, Australia; School of Information Science and Technology, Nantong University, Nantong, China","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","986","1000","Generative adversarial networks (GANs) have been a popular deep generative model for real-world applications. Despite many recent efforts on GANs that have been contributed, mode collapse and instability of GANs are still open problems caused by their adversarial optimization difficulties. In this article, motivated by the cooperative co-evolutionary algorithm, we propose a cooperative dual evolution-based GAN (CDE-GAN) to circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution with respect to the generator(s) and discriminators into a unified evolutionary adversarial framework to conduct effective adversarial multiobjective optimization. Thus, it exploits the complementary properties and injects dual mutation diversity into the training, to steadily diversify the estimated density in capturing multimodes and improve generative performance. Specifically, CDE-GAN decomposes the complex adversarial optimization problem into two subproblems (generation and discrimination), and each subproblem is solved with a separated subpopulation (E-Generators and E-Discriminators), evolved by its own evolutionary algorithm. Additionally, we further propose a Soft Mechanism to balance the tradeoff between E-Generators and E-Discriminators to conduct steady training for CDE-GAN. Extensive experiments on one synthetic dataset and three real-world benchmark image datasets demonstrate that the proposed CDE-GAN achieves a competitive and superior performance in generating good quality and diverse samples over baselines. The code and more generated results are available at our project homepage https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html.","1941-0026","","10.1109/TEVC.2021.3068842","National Natural Science Foundation of China(grant numbers:61571205,61772220,61976120); International Science and Technology Cooperation Programme(grant numbers:2016YFE0121200); Special Projects for Technology Innovation of Hubei Province(grant numbers:2018ACA135); Key Science and Technology Innovation Program of Hubei Province(grant numbers:2017AAA017); Natural Science Foundation of Jiangsu Province BK(grant numbers:20191445); Natural Science Foundation of Hubei Province(grant numbers:2018CFB691); Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:JCYJ20180305180804836,JSGG20180507182030600); ARC DECRA Fellowship(grant numbers:DE220100265); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9386237","Cooperative co-evolutionary algorithm;cooperative dual evolution;evolutionary computation (EC);generative adversarial networks (GANs);multiobjective optimization","Gallium nitride;Optimization;Training;Generators;Generative adversarial networks;Evolutionary computation;Statistics","evolutionary computation;learning (artificial intelligence);neural nets;optimisation","dual evolution-based generative adversarial network;generative adversarial networks;unified evolutionary adversarial framework;effective adversarial multiobjective optimization;complex adversarial optimization problem;E-Generators;deep generative model;CDE-GAN;mode collapse;GAN instability;cooperative dual evolution-based GAN;dual mutation diversity;generative performance;E-Discriminators;soft mechanism","","12","","54","IEEE","25 Mar 2021","","","IEEE","IEEE Journals"
"Empirical Comparison of Search Heuristics for Genetic Improvement of Software","A. Blot; J. Petke","Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","1001","1011","Genetic improvement (GI) uses automated search to improve existing software. It has been successfully used to optimize various program properties, such as runtime or energy consumption, as well as for the purpose of bug fixing. GI typically navigates a space of thousands of patches in search for the program mutation that best improves the desired software property. While genetic programming (GP) has been dominantly used as the search strategy, more recently other search strategies, such as local search, have been tried. It is, however, still unclear which strategy is the most effective and efficient. In this article, we conduct an in-depth empirical comparison of a total of 18 search processes using a set of eight improvement scenarios. Additionally, we also provide new GI benchmarks and we report on new software patches found. Our results show that, overall, local search approaches achieve better effectiveness and efficiency than GP approaches. Moreover, improvements were found in all scenarios (between 15% and 68%). A replication package can be found online: https://github.com/bloa/tevc_2020_artefact.","1941-0026","","10.1109/TEVC.2021.3070271","U.K. EPSRC Fellowship(grant numbers:EP/P023991/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392013","Genetic improvement (GI);genetic programming (GP);search-based software engineering;stochastic local search","Software;Search problems;Genetic programming;Statistics;Sociology;Computer bugs;Navigation","genetic algorithms;program testing;search problems;software engineering","improvement scenarios;GI benchmarks;software patches;local search approaches;search heuristics;genetic improvement;program properties;bug fixing;program mutation;desired software property;genetic programming;search strategy;in-depth empirical comparison;18 search processes","","6","","40","IEEE","31 Mar 2021","","","IEEE","IEEE Journals"
"TechRxiv: Share Your Preprint Research with the World!","",,"IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","1012","1012","Advertisement: TechRxiv is a free preprint server for unpublished research in electrical engineering, computer science, and related technology. TechRxiv provides researchers the opportunity to share early results of their work ahead of formal peer review and publication. Benefits: Rapidly disseminate your research findings; Gather feedback from fellow researchers; Find potential collaborators in the scientific community; Establish the precedence of a discovery; and Document research results in advance of publication. Upload your unpublished research today!","1941-0026","","10.1109/TEVC.2021.3101512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552969","","","","","","","","","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"IEEE Transactions on Evolutionary Computation Society Information","",,"IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","C3","C3","Provides a listing of current committee members and society officers.","1941-0026","","10.1109/TEVC.2021.3101532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552970","","","","","","","","","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"IEEE Transactions on Evolutionary Computation information for authors","",,"IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","C4","C4","These instructions give guidelines for preparing papers for this publication. Presents information for authors publishing in this journal.","1941-0026","","10.1109/TEVC.2021.3101533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552967","","","","","","","","","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
